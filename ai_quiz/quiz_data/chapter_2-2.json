{
    "id": 5,
    "title": "챕터 2-2: 합성 데이터 제작",
    "icon": "🤖",
    "questions": [
        {
            "difficulty": "하",
            "time": "1분",
            "question": "Prompt Engineering의 핵심 목표로 옳은 것은?",
            "options": [
                "모델의 파라미터를 직접 수정하여 성능을 높인다.",
                "적절한 입력 지시어를 설계해 원하는 출력 품질을 얻는다.",
                "모델의 토큰 수를 줄여 학습 속도를 높인다.",
                "모델을 미세조정(fine-tuning) 없이 동작하지 못하게 한다."
            ],
            "correct": 1,
            "explanation": "⓵ 파라미터를 건들지 않고 성능을 높입니다.\n⓶ 입력 지시어를 구체적으로 설계하여 모델의 출력 품질을 높이기 위해 Prompt Engineering을 진행합니다.\n⓷ 토큰 수를 줄이는 목표도 있지만, 학습을 진행하지는 않는 방법이므로 올바르지 않습니다.\n⓸ 미세조정 없이 동작하는 방법론입니다."
        },
        {
            "difficulty": "중",
            "time": "3분",
            "question": "최근 연구에서 LLM as Judge의 신뢰성을 보장하기 위해 자주 사용하는 기법으로 옳지 않은 것은?",
            "options": [
                "Zero-Shot 평가",
                "Self-Consistency (다수 샘플링 후 투표)",
                "Adversarial Prompting (교란 프롬프트 검증)",
                "Chain-of-Thought(CoT) 기반 평가"
            ],
            "correct": 0,
            "explanation": "⓵ 정답. Zero-Shot을 하게 되면 일관된 평가를 얻기 어렵습니다.\n⓶ LLM as Judge는 CoT reasoning을 통해 평가 과정의 설명가능성을 높입니다.\n⓷ Self-Consistency는 여러 샘플링을 통해 편향을 줄이고 안정성을 확보합니다.\n⓸ Adversarial Prompting은 평가자가 교란 입력에 얼마나 강건한지 검증하는 방식입니다."
        },
        {
            "difficulty": "상",
            "time": "4분",
            "question": "합성 데이터를 대규모로 학습에 포함할 경우 발생할 수 있는 대표적인 위험은 무엇인가?",
            "options": [
                "데이터 증강 효과로 generalization gap이 감소한다.",
                "모델 파라미터 수가 자동으로 증가한다.",
                "합성 데이터가 원본 데이터를 대체하여 과적합 위험이 줄어든다.",
                "모델이 synthetic-specific bias를 학습하여 실제 데이터 분포와 괴리가 생긴다."
            ],
            "correct": 3,
            "explanation": "⓵ generalization gap이 줄어들 수 있습니다. 이는 합성 데이터를 사용했을 때의 이점이지 위험이 아닙니다.\n⓶ 모델 파라미터 수는 고정입니다.\n⓷ 합성 데이터는 원본 데이터를 완벽히 대체할 수 없습니다. 합성 데이터의 퀄리티는 원본 데이터보다 떨어집니다.\n⓸ 정답. Synthetic data는 분포 왜곡(distribution shift) 문제를 일으킬 수 있으며, 실제 환경에서 성능이 저하될 수 있습니다."
        },
        {
            "difficulty": "하",
            "time": "1분",
            "question": "다음 중 데이터 증강(Data Augmentation) 과 합성 데이터(Synthetic Data) 의 차이에 대한 설명으로 가장 적절한 것은?",
            "options": [
                "데이터 증강은 전혀 존재하지 않는 새로운 데이터를 만드는 과정이고, 합성 데이터는 기존 데이터를 변형하는 과정이다.",
                "두 방법 모두 동일하게 원본 데이터를 복사하는 과정에 불과하다.",
                "데이터 증강은 API를 사용하지 않고, 합성 데이터는 반드시 API를 통해서만 가능하다.",
                "데이터 증강은 기존 데이터를 다양한 방식으로 변형하여 새로운 학습 샘플을 만드는 과정이고, 합성 데이터는 프롬프트 기반으로 가상의 데이터를 생성하는 과정이다."
            ],
            "correct": 3,
            "explanation": "⓵ 설명이 반대입니다. 증강은 원본 기반 변형, 합성은 새로운 데이터 생성입니다.\n⓶ 단순 복사가 아니라 변형/생성을 통해 다양성을 늘리는 과정입니다.\n⓷ 증강과 합성 모두 API 사용 여부와 무관하게 가능하며, API는 단지 도구일 뿐입니다.\n⓸ 정답. 데이터 증강은 원본 데이터를 변형(치환, 역번역, 노이즈 추가 등)하여 분포를 풍부하게 만드는 과정이고, 합성 데이터는 실제로 존재하지 않는 새로운 샘플을 모델(예: LLM 프롬프트)로부터 직접 생성하는 과정입니다."
        },
        {
            "difficulty": "중",
            "time": "3분",
            "question": "다음 중 LLM as a Judge를 평가 자동화 도구로 활용할 때 발생할 수 있는 한계로 옳지 않은 것은?",
            "options": [
                "평가자의 응답이 프롬프트 설계에 민감하다.",
                "인간 평가를 대체할 만큼의 퀄리티가 보장된다.",
                "편향(Bias)이 평가 결과에 반영될 수 있다.",
                "다수의 샘플 평가 시 비용 문제가 발생할 수 있다."
            ],
            "correct": 1,
            "explanation": "⓵ 프롬프트를 어떻게 넣느냐에 따라 평가가 아예 달라질 수 있습니다.\n⓶ 정답. 최근 LLM 모델들의 성능이 좋아 사람의 평가를 대체할 수준이 되긴 하지만 가장 좋은 방법은 사람이 평가하는 것입니다.\n⓷ 프롬프트를 설계하는 사람, 모델의 특성 등 편향이 평가 결과에 반영됩니다.\n⓸ 정확한 평가를 얻기 위해서는 여러 샘플을 평가해야 하므로 비용이 점점 증가합니다."
        }
    ]
}