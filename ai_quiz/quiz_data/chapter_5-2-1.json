{
    "id": 12,
    "title": "챕터 5-2(1): On-Device AI를 위한 LM 미세조정",
    "icon": "📱",
    "questions": [
        {
            "difficulty": "하",
            "time": "1분",
            "question": "LLM(대규모 언어 모델)을 활용하여 특정 목적(예: 의도 분류)의 데이터셋을 자동으로 생성하는 방식의 가장 큰 장점은 무엇인가요?",
            "options": [
                "LLM 모델 자체의 최종 성능을 정확하게 평가할 수 있다.",
                "데이터 구축에 드는 시간과 비용을 절감하고, 필요에 맞는 데이터를 대량으로 확보할 수 있다.",
                "생성된 데이터의 파일 형식을 CSV나 JSONL 등으로 표준화할 수 있다.",
                "소형 언어 모델(SLM)의 학습 과정을 대신할 수 있다."
            ],
            "correct": 1,
            "explanation": "⓵ 이 과정의 목표는 데이터셋 생성이며, 데이터 생성용 LLM의 성능을 평가하는 것이 아닙니다.\n⓶ 고품질의 텍스트 데이터를 프로그래밍 방식으로 생성함으로써, 특정 태스크에 맞는 학습 데이터를 구하기 어려운 경우 시간과 비용을 절감하는 효과적인 대안이 될 수 있습니다.\n⓷ 파일 형식 표준화는 LLM이 아닌 데이터 처리 도구(예: pandas)의 역할입니다.\n⓸ LLM으로 생성한 데이터는 SLM을 '학습'시키기 위한 재료이며, 학습 과정 자체를 대체하지는 않습니다."
        },
        {
            "difficulty": "중",
            "time": "4분",
            "question": "실습에서는 소형 언어 모델(SLM)을 '전체 파인튜닝'하는 대신 'PEFT(LoRA)' 기법을 사용했습니다. 이 선택이 가져오는 가장 중요한 장점과 그로 인해 발생하는 결과를 올바르게 연결한 것은 무엇인가요?",
            "options": [
                "장점: 모델의 전체 파라미터 수를 영구적으로 줄여 추론 속도를 향상시킨다. / 결과: 학습된 가중치는 '어댑터(Adapter)'라는 별도의 작은 파일로 저장된다.",
                "장점: 원본 모델의 가중치는 그대로 두고 일부 파라미터만 추가하여 학습하므로, 계산 비용과 메모리 사용량이 매우 효율적이다. / 결과: 학습된 '어댑터'는 원본 모델과 독립적으로 존재하며, 필요시 병합(merge)하여 배포용 모델을 만들 수 있다.",
                "장점: LLM으로 생성된 합성 데이터셋에 적용할 수 있어, 데이터 품질에 대한 의존도를 낮춘다. / 결과: 학습이 완료되면 원본 모델 파일(base_model) 자체가 변경된 상태로 저장된다.",
                "장점: 학습 과정을 단순화하여 optimizer나 loss function을 직접 설정할 필요가 없다. / 결과: 학습된 모델은 반드시 HuggingFaceTB/SmolLM2-135M-Instruct 모델과 함께 사용해야 한다."
            ],
            "correct": 1,
            "explanation": "⓵ LoRA의 핵심은 원본 모델(frozen base model)을 건드리지 않고, 학습 가능한 작은 행렬(adapter)들을 추가하여 학습하는 것입니다. 이로 인해 학습이 매우 빠르고 효율적이며, 결과물인 '어댑터'는 원본 모델과 분리하여 관리할 수 있습니다. 실습에서도 model.save_pretrained(peft_save_dir)를 통해 어댑터만 저장하고, 이후 merged.merge_and_unload()로 병합하는 과정을 거쳤습니다.\n⓶ LoRA는 추론 시 어댑터를 병합하면 파라미터 수가 원본과 같아지므로, 추론 속도 향상이 주된 장점은 아닙니다. '학습 효율성'이 핵심입니다.\n⓷ PEFT 기법은 데이터셋의 종류(합성/실제)와 무관하게 적용 가능하며, 원본 모델 파일은 변경되지 않고 어댑터 파일이 별도로 생성됩니다.\n⓸ LoRA를 사용하더라도 옵티마이저, 손실 함수 설정 및 학습 루프 구현은 필수적입니다. 또한, 학습된 어댑터는 동일한 구조를 가진 다른 베이스 모델에도 이론적으로 적용 가능합니다."
        },
        {
            "difficulty": "상",
            "time": "5분",
            "question": "6개의 세분화된 '의도(Intent)'를 '소형'과 '대형' 단 2개의 모델로 라우팅해야 하는 상황을 가정해 보자. 이 라우팅을 담당할 분류 모델을 가장 효율적으로 학습시키면서, 동시에 문제 자체의 복잡도를 낮추는 가장 근본적인 접근 방식은 무엇일까?",
            "options": [
                "소형 모델과 대형 모델의 특징을 모두 학습할 수 있는 Mixture of Experts (MoE) 아키텍처를 도입하여, 6개의 의도를 입력받아 2개의 모델 중 하나로 바로 연결되도록 설계한다.",
                "전체 파인튜닝 대신 LoRA 기법을 사용하여 6개 의도 분류를 위한 파라미터만 학습시킨 후, 마지막 출력층(output layer)에서 결과를 2개의 모델로 그룹화한다.",
                "각 6개 의도에 대해 LLM으로 데이터를 대량 생성하여, 데이터의 양으로 모델이 스스로 2개의 그룹(소형/대형)을 학습하도록 유도한다.",
                "6개의 의도를 직접 분류하는 다중 클래스 분류(Multi-class Classification) 문제로 접근하는 대신, 각 의도와 복잡도에 대한 규칙을 먼저 데이터에 적용해 '소형/대형'이라는 2개의 레이블로 변환한다. 그 후, 변환된 이진 분류(Binary Classification) 데이터셋으로 모델을 학습시킨다."
            ],
            "correct": 3,
            "explanation": "⓵ MoE와 같은 복잡한 아키텍처를 도입하는 것은 문제의 복잡도를 낮추는 것이 아니라, 복잡한 문제를 해결하기 위해 모델의 복잡도를 높이는 방향이므로 비효율적일 수 있습니다.\n⓶ LoRA는 학습 '기법'의 효율성을 높이는 것이지, 6개 클래스 분류라는 문제의 '난이도' 자체를 낮추지는 못합니다. 문제의 본질은 그대로 둔 채 푸는 방식만 바꾸는 것입니다.\n⓷ 단순히 데이터 양을 늘리는 것은, 모델이 어려운 문제(6개 클래스 분류)를 더 많은 예제로 학습하게 하는 것일 뿐, 문제 자체를 더 쉬운 문제(2개 클래스 분류)로 바꾸는 근본적인 해결책은 아닙니다.\n⓸ 가장 효율적인 접근법은 모델이나 학습 기법을 복잡하게 만들기 전에, 문제 자체를 단순화하는 것입니다. 6개의 클래스를 분류하는 것보다 2개의 클래스를 분류하는 것이 훨씬 쉬운 문제이므로, 데이터 생성 단계에서부터 규칙을 적용해 최종 목표인 'small'/'large' 레이블을 미리 만들어주는 것이 핵심입니다."
        },
        {
            "difficulty": "하",
            "time": "2분",
            "question": "데이터 준비 과정에서 train_test_split 함수를 두 번 사용하여 전체 데이터를 학습, 검증, 테스트용으로 분할했습니다. '검증(validation) 데이터셋'의 주된 역할은 무엇인가요?",
            "options": [
                "모델의 최종 성능을 외부에 보고하기 위한 용도이다.",
                "LLM이 생성한 데이터에 오류가 없는지 검수하기 위한 용도이다.",
                "모델을 학습시키는 데 직접적으로 사용되는 데이터이다.",
                "모델이 학습 중에 과적합(overfitting)되는지 확인하고, 최적의 학습 시점을 판단하기 위한 용도이다."
            ],
            "correct": 3,
            "explanation": "⓵ 모델의 최종 성능 보고에는 학습과 검증 과정에서 한 번도 사용되지 않은 '테스트(test) 데이터셋'을 사용하는 것이 일반적입니다.\n⓶ 데이터의 오류 검수는 일반적으로 데이터 전처리 단계에서 수행하며, 검증 데이터셋의 역할과는 다릅니다.\n⓷ 모델을 직접 학습시키는 데 사용되는 데이터는 '학습(train) 데이터셋'입니다.\n⓸ 검증 데이터셋은 학습에 직접 사용되지는 않지만, 각 에포크(epoch) 학습이 끝날 때마다 모델의 성능을 평가하는 데 사용됩니다. 이를 통해 모델이 훈련 데이터에만 과도하게 최적화(과적합)되고 있는지, 아니면 새로운 데이터에도 잘 일반화되고 있는지를 모니터링할 수 있습니다."
        },
        {
            "difficulty": "중",
            "time": "2분",
            "question": "LoRA와 같은 PEFT 기법으로 모델을 파인튜닝한 후, 실제 서비스에 배포(deploy)할 때는 학습된 '어댑터'와 '원본 모델'을 하나로 합치는 단계를 거치는 것이 일반적입니다. 이 과정을 수행하는 가장 주된 이유는 무엇인가요?",
            "options": [
                "원본 모델과 어댑터를 합치면 추론 시 추가적인 계산이 필요 없어지므로, 배포 환경에서 더 효율적이고 간편하게 모델을 운영할 수 있다.",
                "모델의 전체 파일 크기를 어댑터 수준으로 대폭 줄여 저장 공간을 절약하기 위함이다.",
                "합쳐진 모델로 추가 파인튜닝을 진행하여 성능을 더욱 높이기 위함이다.",
                "향후 다른 태스크에 원본 모델을 재사용하기 위해, 학습된 어댑터 정보를 분리하여 백업하기 위함이다."
            ],
            "correct": 0,
            "explanation": "⓵ LoRA는 학습 시에만 원본 모델 위에 어댑터를 두고 추가 계산을 수행합니다. 추론 시에는 이 둘을 하나의 모델로 합쳐 LoRA 구조가 없는 일반 모델처럼 만들면, 구조가 단순해지고 관리가 용이해져 배포 환경에 더 적합합니다.\n⓶ 이 과정은 작은 어댑터를 큰 원본 모델에 합치는 것이므로, 파일 크기는 원본 모델과 비슷해지며 줄어들지 않습니다.\n⓷ 모델 병합은 일반적으로 학습이 모두 완료된 후, 추론 및 배포를 준비하는 마지막 단계에서 수행합니다.\n⓸ 이 과정은 어댑터를 '분리(unmerge)'하는 것이 아니라 '병합(merge)'하는 것으로, 설명과 반대되는 작업입니다."
        }
    ]
}