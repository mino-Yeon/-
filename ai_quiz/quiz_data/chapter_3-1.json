{
    "id": 6,
    "title": "챕터 3-1: CNN 실습",
    "icon": "🖼️",
    "questions": [
        {
            "difficulty": "하",
            "time": "1분",
            "question": "'선형 프로빙(Linear Probing)' 단계에 대한 설명으로 가장 올바른 것은 무엇인가요?",
            "options": [
                "모델의 모든 계층을 처음부터 학습시켜 새로운 데이터에 적응시킨다.",
                "사전 학습된 모델의 특징 추출 부분(대부분의 계층)은 고정하고, 마지막 분류층만 새로 학습시킨다.",
                "데이터 증강(Augmentation) 기법을 사용하여 모델 전체를 미세 조정(Fine-tuning)한다.",
                "HuggingFace에서 ViT 모델을 불러와 학습 없이 추론만 수행한다."
            ],
            "correct": 1,
            "explanation": "⓵ 모델의 모든 계층을 처음부터 학습시키는 것은 'Scratch' 학습이라고 하며, 전이 학습과는 다릅니다.\n⓶ 선형 프로빙은 사전 학습된 모델의 강력한 특징 추출 능력을 그대로 활용하면서, 새로운 과제에 맞게 분류층만 빠르게 학습시키는 전이 학습의 한 방법입니다. 실습에서는 param.requires_grad = False 코드를 통해 마지막 fc 층을 제외한 모든 계층을 동결(freeze)했습니다.\n⓷ 데이터 증강과 모델 전체 미세 조정은 실습의 두 번째 파트에서 성능을 더욱 향상시키기 위해 사용된 기법입니다.\n⓸ ViT 모델을 활용한 추론은 실습의 세 번째 파트 내용입니다."
        },
        {
            "difficulty": "중",
            "time": "3분",
            "question": "실습에서 transforms.RandomCrop(32, padding=4)와 transforms.RandomHorizontalFlip()을 훈련 데이터에만 적용했습니다. 이 두 가지 데이터 증강 기법의 가장 핵심적인 목표와 테스트 데이터에 적용하지 않는 이유를 올바르게 짝지은 것은 무엇인가요?",
            "options": [
                "목표: 훈련 이미지의 절대적인 개수를 늘려 학습 속도를 높인다. / 이유: 테스트 데이터에 적용하기에는 연산 비용이 너무 크기 때문이다.",
                "목표: 모델이 객체의 위치, 크기 및 좌우 방향 변화에 강건해지도록(Robust/Invariant) 학습시킨다. / 이유: 왜곡되지 않은 원본 데이터에 대한 모델의 성능을 일관되고 공정하게 평가해야 하기 때문이다.",
                "목표: 모든 이미지를 ResNet 입력 크기인 224x224로 통일시킨다. / 이유: 테스트 데이터는 이미 객체가 완벽하게 중앙에 위치해 증강이 불필요하기 때문이다.",
                "목표: 이미지 픽셀 값의 분포를 정규화하여 학습 안정성을 높인다. / 이유: 테스트 데이터에 증강을 적용하면 훈련 과정에 데이터 정보가 유출(leakage)되기 때문이다."
            ],
            "correct": 1,
            "explanation": "핵심 목표: RandomCrop은 객체가 이미지의 다른 위치에 있어도 인식하게 하고, RandomHorizontalFlip은 고양이의 왼쪽 얼굴과 오른쪽 얼굴을 모두 학습하게 하여 모델의 일반화 성능을 극대화하고 불변성(Invariance) 특성을 갖게 하는 것이 핵심입니다.\n테스트 데이터 미적용 이유: 모델의 성능 평가는 언제나 동일한 척도로 이루어져야 합니다. 테스트 시에만 이미지를 무작위로 변경한다면, 평가 결과의 신뢰도가 떨어지고 다른 모델과의 공정한 비교가 불가능해집니다. 따라서 평가의 일관성을 확보하기 위해 원본 그대로 사용합니다.\n⓵ 데이터 증강은 학습의 다양성을 높이는 것이지, 이미지 개수를 물리적으로 늘리거나 학습 속도를 높이는 것이 주 목적이 아닙니다.\n⓷ 이미지 크기 변경은 transforms.Resize()가 수행하는 역할입니다.\n⓸ 픽셀 분포 정규화는 transforms.Normalize()의 역할입니다."
        },
        {
            "difficulty": "상",
            "time": "5분",
            "question": "ResNet과 ViT는 특징(feature)을 학습하는 방식에서 근본적인 차이가 있습니다. 실습 코드와 설명을 바탕으로, 두 모델이 이미지의 '고양이'를 인식할 때 내부적으로 집중하는 정보의 특성을 가장 잘 대비시킨 것은 무엇인가요?",
            "options": [
                "ResNet: 이미지의 전체적인 색상 분포에 집중한다. / ViT: 이미지 내 객체의 외곽선(shape) 정보에 집중한다.",
                "ResNet: model.fc만 수정하면 되므로 구조 변경이 용이하다. / ViT: 사전 학습된 그대로만 사용해야 하므로 구조 변경이 불가능하다.",
                "ResNet: 선형 프로빙(Linear Probing) 방식으로만 특징을 학습한다. / ViT: 미세 조정(Fine-tuning) 방식으로만 특징을 학습한다.",
                "ResNet: 국소적인 패턴(edge, texture)에서 시작해 계층적으로 조합된 특징(눈, 코, 귀)에 집중한다. / ViT: 이미지를 나눈 각 패치(patch)들 간의 전역적인(global) 상호 관계성에 집중한다."
            ],
            "correct": 3,
            "explanation": "⓵ 두 모델 모두 색상, 질감, 형태 등 이미지의 모든 시각적 정보를 종합적으로 활용합니다.\n⓶ 두 모델 모두 전이 학습 시 최종 분류층을 변경하는 것은 동일하며, 이는 모델의 고유 특성이 아닌 활용 방법의 차이입니다. 실습에 사용된 ViT 모델도 CIFAR-10에 맞게 최종 분류층이 10개로 미세 조정된 모델입니다.\n⓷ 선형 프로빙과 미세 조정은 모델을 학습시키는 '전략'이지, ResNet과 ViT 아키텍처 자체에 귀속된 학습 방식이 아닙니다.\n⓸ 이것이 CNN과 Transformer의 가장 핵심적인 작동 방식의 차이입니다. ResNet(CNN)은 합성곱 필터를 통해 이미지의 지역적인 정보를 점차 더 복잡하고 추상적인 계층적 특징으로 만들어가는 반면, ViT는 이미지를 바둑판처럼 나눈 패치들이 이미지 전체에서 서로 어떤 연관성을 갖는지 전역적인 관계를 파악하여 이미지를 이해합니다."
        },
        {
            "difficulty": "하",
            "time": "1분",
            "question": "실습 마지막 파트에서 HuggingFace의 pipeline을 사용했습니다. 이 pipeline을 사용했을 때의 가장 큰 장점은 무엇인가요?",
            "options": [
                "모델을 처음부터 훈련시키는 과정을 자동화해준다.",
                "이미지 데이터를 증강(augmentation)하는 다양한 기법을 추천해준다.",
                "복잡한 전처리, 모델 추론, 후처리 과정을 하나의 간단한 함수 호출로 처리해준다.",
                "학습된 모델의 구조를 시각화하는 그래프를 생성해준다."
            ],
            "correct": 2,
            "explanation": "⓵ 데이터 증강은 모델의 성능을 높이기 위해 훈련(Training) 단계에서 사용되는 기법으로, pipeline의 추론 기능과는 직접적인 관련이 없습니다.\n⓶ pipeline은 이미 학습된 모델을 사용하는 추론(Inference) 기능을 위한 것이며, 모델을 훈련시키는 기능은 수행하지 않습니다.\n⓷ pipeline은 특정 태스크(예: 이미지 분류)에 필요한 전처리, 모델 추론, 결과 해석까지의 모든 단계를 하나의 함수로 캡슐화합니다. 실습에서도 clf(sample_images) 코드 한 줄로 복잡한 과정을 처리하여 손쉽게 예측 결과를 얻을 수 있었습니다.\n⓸ 모델의 구조를 시각화하는 것은 torchsummary나 TensorBoard와 같은 별도의 라이브러리가 수행하는 역할이며, pipeline의 주요 기능이 아닙니다."
        },
        {
            "difficulty": "중",
            "time": "3분",
            "question": "2단계 '미세 조정' 파트에서 optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1) 코드를 사용했습니다. 이 학습률 스케줄러(Learning Rate Scheduler)의 역할에 대한 설명으로 가장 정확한 것은 무엇인가요?",
            "options": [
                "5 에포크(epoch)마다 학습률을 0.1만큼씩 점진적으로 '증가'시켜 학습을 가속화한다.",
                "모델의 손실(loss)이 5번 이상 개선되지 않으면 학습률을 이전의 0.1배로 '감소'시킨다.",
                "학습을 5 에포크(epoch) 진행할 때마다, 학습률(learning rate)을 이전의 0.1배로 '감소'시켜 모델이 더 정교하게 최적화되도록 돕는다.",
                "전체 학습 과정 동안 학습률을 0.1로 '고정'하여 안정적인 학습을 보장한다."
            ],
            "correct": 2,
            "explanation": "⓵ StepLR은 이름 그대로 특정 단계(step)마다 학습률을 조정하는 스케줄러입니다.\n⓶ step_size=5는 '5 에포크마다'를 의미하고, gamma=0.1은 학습률에 0.1을 곱하라는 의미입니다.\n⓷ 학습 초기에는 비교적 큰 학습률로 빠르게 최적점에 가까워진 뒤, 학습이 진행됨에 따라 학습률을 낮춰 최적점에 더 세밀하게 수렴하도록 돕는 역할을 합니다.\n⓸ (2)번 보기는 손실 값을 기준으로 학습률을 조정하는 ReduceLROnPlateau 스케줄러에 대한 설명으로, 본 실습에서 사용한 StepLR과는 작동 방식이 다릅니다."
        }
    ]
}