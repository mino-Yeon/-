{
    "id": 7,
    "title": "챕터 3-2: 이미지 생성 실습",
    "icon": "🎨",
    "questions": [
        {
            "difficulty": "하",
            "time": "1분",
            "question": "본 실습에서 사용한 CLIP 모델과 ResNet 모델의 가장 핵심적인 차이점은 무엇인가?",
            "options": [
                "CLIP은 이미지 생성을, ResNet은 텍스트 생성을 주로 수행한다.",
                "CLIP은 이미지와 텍스트의 의미적 유사도를 평가하고, ResNet은 이미지를 정해진 카테고리로 분류한다.",
                "CLIP은 ResNet보다 항상 더 빠르고 가볍게 동작한다.",
                "CLIP은 합성 데이터로만 학습할 수 있고, ResNet은 실제 데이터로만 학습할 수 있다."
            ],
            "correct": 1,
            "explanation": "⓵ 두 모델 모두 이미지 및 텍스트를 생성하는 기능은 없습니다.\n⓶ ResNet은 이미지를 보고 '이것은 87번 클래스'처럼 정해진 카테고리로 분류하는 반면, CLIP은 \"이 이미지는 '수채화 고양이'라는 텍스트와 얼마나 의미가 비슷한가?\"를 유사도 점수로 알려줍니다.\n⓷ 모델의 속도나 크기는 아키텍처의 세부 버전에 따라 다르므로 항상 그렇다고 할 수 없습니다. 예를 들어 ResNet-18은 매우 가볍습니다. 이는 두 모델의 핵심적인 기능 차이가 아닙니다.\n⓸ 두 모델 모두 실제 데이터로 학습되었으며, 합성 데이터로 특정 모델을 학습시키는 것은 '기법'이지 모델 자체의 제약 사항이 아닙니다."
        },
        {
            "difficulty": "중",
            "time": "2분",
            "question": "생성 AI가 만든 합성 데이터(Synthetic Data)만으로 학습된 모델을 실제 세상의 이미지에 적용할 때 발생할 수 있는 가장 치명적인 문제와 그 원인으로 적절한 것은 무엇인가?",
            "options": [
                "합성 데이터는 항상 실제 데이터보다 품질이 낮아 모델의 정확도가 떨어진다.",
                "생성 모델 특유의 화풍이나 미세한 패턴까지 모델이 학습하게 되어, 실제 이미지와 분포 차이 때문에 일반화 성능이 저하될 수 있다.",
                "합성 데이터는 저작권 문제가 발생할 수 있어 상업적으로 활용하는 것이 불가능하다.",
                "합성 데이터로 학습하면 모델의 추론(Inference) 속도가 실제 데이터로 학습했을 때보다 현저히 느려진다."
            ],
            "correct": 1,
            "explanation": "⓵ 생성 데이터의 품질은 매우 높을 수 있으며, 항상 품질이 낮다고 단정할 수 없습니다. 문제의 핵심은 품질보다 데이터의 분포 차이입니다.\n⓶ 이것이 도메인 간극의 핵심 문제입니다. 모델이 데이터의 본질적인 특징 대신, 특정 생성 모델이 만들어내는 인공적인 패턴이나 스타일에 과적합되어, 그런 패턴이 없는 실제 이미지에 대한 일반화 성능이 떨어지는 심각한 문제가 발생할 수 있습니다.\n⓷ 합성 데이터는 실제 사진과 달리 저작권 문제에서 비교적 자유롭다는 것이 큰 장점 중 하나이며, 상업적 활용을 위해 연구되고 있습니다.\n⓸ 모델의 추론 속도는 학습된 가중치 값이나 학습 데이터의 종류가 아닌, 모델의 아키텍처(구조)와 하드웨어에 의해 결정됩니다."
        },
        {
            "difficulty": "상",
            "time": "3분",
            "question": "Stable Diffusion 의 각 컴포넌트에 대한 설명으로 옳지 않은 것은 무엇인가?",
            "options": [
                "CLIP 텍스트 인코더(Text Encoder): 입력된 텍스트 프롬프트를 U-Net이 이해할 수 있는 숫자 벡터(임베딩)로 변환하는 역할을 한다.",
                "U-Net 노이즈 예측기: 텍스트 임베딩의 가이드를 받아, 랜덤 노이즈 이미지로부터 점진적으로 노이즈를 제거하며 이미지의 잠재 표현(Latent Representation)을 생성한다.",
                "VAE 디코더(Image Decoder): U-Net이 생성한 저차원의 잠재 표현을 사람이 볼 수 있는 고해상도 픽셀 이미지로 변환한다.",
                "VAE 인코더(Image Encoder): 생성 과정 마지막에 최종 이미지를 여러 개의 카테고리로 분류하여 가장 적합한 이미지만을 선택하는 역할을 한다."
            ],
            "correct": 3,
            "explanation": "⓵ 모델은 텍스트를 바로 이해하지 못하기 때문에 CLIP 텍스트 인코더를 사용해 이 텍스트를 AI가 이해할 수 있는 언어, 즉 숫자 벡터(임베딩)로 번역하는 과정을 거칩니다.\n⓶ U-Net은 텍스트 인코더의 출력을 참고하여 순수한 노이즈에서부터 점차 노이즈를 제거해가며 이미지의 형태를 서서히 만들어나갑니다.\n⓷ U-Net이 완성한 결과물은 아직 우리가 볼 수 있는 이미지 형태가 아닌, 압축된 잠재 공간(Latent Space)의 표현입니다. VAE 디코더는 이 압축 표현을 사람이 볼 수 있는 이미지로 변환합니다.\n⓸ 이미지를 카테고리로 분류하는 것은 분류 모델(Classifier)의 역할이며, Stable Diffusion의 생성 과정에는 포함되지 않습니다."
        },
        {
            "difficulty": "하",
            "time": "1분",
            "question": "이미지 생성 시, 부정 프롬프트(negative prompt) 으로 가장 적절한 예시는 무엇인가?",
            "options": [
                "a photo of a cat",
                "masterpiece, high quality",
                "blurry, low resolution, bad anatomy",
                "runwayml/stable-diffusion-v1-5"
            ],
            "correct": 2,
            "explanation": "⓵ 해당 항목은 무엇을 그릴지 지시하는 긍정 프롬프트에 해당합니다.\n⓶ 이것은 결과물의 품질을 높이기 위해 주로 긍정 프롬프트에 추가하는 키워드들입니다.\n⓷ 부정 프롬프트의 목적은 원하지 않는 요소를 배제하는 것입니다. 이미지의 품질을 저해하는 요소를 명시하는 것이 올바른 사용법입니다.\n⓸ 이것은 프롬프트가 아니라 허깅페이스 허브에서 모델을 불러올 때 사용하는 모델 id 입니다."
        },
        {
            "difficulty": "중",
            "time": "2분",
            "question": "Stable Diffusion과 같은 거대 언어-이미지 파운데이션 모델(Foundation Model)을 사용하여 특정 클래스의 데이터를 생성할 때, 발생할 수 있는 잠재적인 문제점으로 가장 적절한 것은 무엇인가?",
            "options": [
                "모드 붕괴(Mode Collapse): 생성 모델이 학습 데이터의 특정 모드(mode)에만 치우쳐, 프롬프트를 약간씩 바꿔도 거의 동일하고 단조로운 이미지만 생성하는 현상이 발생한다.",
                "편향 증폭(Bias Amplification): Stable Diffusion을 사전 학습시킨 원본 데이터셋에 내재된 편향(특정 품종의 고양이, 특정 구도 등)이 생성된 합성 데이터셋에 그대로, 혹은 더 증폭되어 반영될 수 있다.",
                "치명적 망각(Catastrophic Forgetting): 고양이 이미지를 생성한 직후 강아지 이미지를 생성하면, 모델이 고양이를 생성하는 능력을 잃어버리게 된다.",
                "라벨 노이즈(Label Noise): 생성된 이미지에 프롬프트와 전혀 상관없는 객체가 포함되거나, 고양이 프롬프트로 강아지 이미지가 생성되는 등 라벨과 데이터의 불일치가 높은 비율로 발생한다."
            ],
            "correct": 1,
            "explanation": "⓵ 모드 붕괴는 주로 GAN(적대적 생성 신경망) 계열의 모델에서 발생하는 고질적인 문제입니다. Stable Diffusion과 같은 Diffusion 모델은 학습 방식의 특성상 GAN에 비해 모드 붕괴 문제에서 훨씬 자유롭고 다양한 결과물을 생성하는 경향이 있습니다.\n⓶ Stable Diffusion은 인터넷의 방대한 이미지로 학습되었고, 그 데이터 안에는 사회적, 문화적, 통계적 편향이 포함되어 있습니다. 예를 들어, 인터넷에 '샴 고양이' 이미지가 압도적으로 많았다면, 우리가 단순히 '고양이'라고 생성해도 특정 품종이 더 자주 나타날 수 있습니다. 이렇게 생성된 편향된 데이터셋으로 하위 모델(ResNet)을 학습시키면, 그 편향이 증폭되어 특정 데이터에만 과적합되는 결과를 낳을 수 있습니다.\n⓷ 치명적 망각은 하나의 모델을 여러 다른 작업(Task)에 순차적으로 학습(training)시킬 때, 이전 작업을 잊어버리는 현상입니다. 본 실습처럼 이미 학습된 모델을 단순히 사용(inference)하여 이미지를 생성하는 경우에는 발생하지 않습니다.\n⓸ 최신 Text-to-Image 모델들은 프롬프트에 대한 충실도(fidelity)가 매우 높습니다. 물론 가끔 실패 사례가 나올 수는 있지만, 이것이 데이터셋의 신뢰도를 떨어뜨릴 만큼 높은 비율로 발생하는 주된 이론적 문제점이라고 보기는 어렵습니다. 문제의 핵심은 성공적으로 생성된 이미지 안에 숨어있는 보이지 않는 편향입니다."
        }
    ]
}