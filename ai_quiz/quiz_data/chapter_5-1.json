{
    "id": 11,
    "title": "챕터 5-1: PEFT(파라미터 효율적 튜닝) 실습",
    "icon": "⚡",
    "questions": [
        {
            "difficulty": "하",
            "time": "1분",
            "question": "LoRA와 Full Fine-Tuning의 차이를 올바르게 설명한 것은?",
            "options": [
                "LoRA는 모든 파라미터를 업데이트하고, Full Fine-Tuning은 일부만 업데이트한다.",
                "둘 다 모든 파라미터를 학습하되, LoRA는 학습률만 다르다.",
                "LoRA는 추가 파라미터만 학습하여 효율성을 높이고, Full Fine-Tuning은 모든 파라미터를 업데이트한다.",
                "LoRA는 학습 속도가 느리지만 더 정확하다."
            ],
            "correct": 2,
            "explanation": "⓵ LoRA는 일부 파라미터만 업데이트하고 Full Fine-Tuning은 모든 파라미터를 업데이트합니다.\n⓶ 학습률은 동일하되 업데이트하는 파라미터가 다릅니다.\n⓷ 정답.\n⓸ LoRA는 일부 파라미터만 학습하기 때문에 학습 속도가 빠르지만 덜 정확할 수 있습니다."
        },
        {
            "difficulty": "중",
            "time": "2분",
            "question": "LoRA fine-tuning 후, 추론 시 모델은 어떤 방식으로 동작하는가?",
            "options": [
                "Base 모델 가중치와 LoRA 업데이트(\\Delta W)를 합쳐서 최종 가중치를 구성한다.",
                "Base 모델만 사용하고 LoRA는 무시한다.",
                "LoRA 업데이트만 사용하고 Base 모델은 무시한다.",
                "LoRA는 추론 시 제거되어 메모리 절약만 한다."
            ],
            "correct": 0,
            "explanation": "추론 단계에서 모델은 Base Weight + LoRA 업데이트(∆𝑊)를 합산하여 최종 출력을 계산합니다."
        },
        {
            "difficulty": "상",
            "time": "4분",
            "question": "LoRA와 Adapter 기법의 차이에 대한 설명으로 옳은 것은?",
            "options": [
                "둘 다 기존 가중치를 완전히 교체한다.",
                "Adapter는 저랭크 행렬 학습이고, LoRA는 추가 MLP 삽입이다.",
                "LoRA는 기존 가중치에 저랭크 업데이트를 추가하는 방식이고, Adapter는 별도의 작은 네트워크를 삽입한다.",
                "LoRA와 Adapter는 완전히 동일한 방식이다."
            ],
            "correct": 2,
            "explanation": "LoRA: 저랭크 행렬 곱을 추가하여 파라미터 효율적 튜닝 수행.\nAdapter: Transformer 블록 사이에 작은 신경망 모듈을 삽입.\n둘 다 PEFT지만 원리와 구조가 다릅니다."
        },
        {
            "difficulty": "하",
            "time": "1분",
            "question": "LoRA(Low-Rank Adaptation)의 주요 장점으로 옳은 것은?",
            "options": [
                "모든 파라미터를 학습해 모델 정확도를 최대화한다.",
                "저랭크 행렬을 추가하여 효율적으로 fine-tuning할 수 있다.",
                "토크나이저만 학습하여 속도를 높인다.",
                "모델 구조를 완전히 새로 학습시킨다."
            ],
            "correct": 1,
            "explanation": "LoRA는 전체 파라미터를 업데이트하지 않고, 저랭크 행렬을 삽입하여 일부만 학습하기 때문에 효율적인 파인튜닝이 가능합니다."
        },
        {
            "difficulty": "중",
            "time": "3분",
            "question": "LoRA는 기존 가중치 행렬 𝑊 ∈ 𝑅^(𝑑×𝑘)를 고정(freeze)한 채, 추가 행렬 𝐴 ∈ 𝑅^(𝑑×𝑟), 𝐵 ∈ 𝑅^(𝑟×𝑘)를 학습합니다. 이때 업데이트된 출력은 다음 중 어떤 수식으로 표현되는가?",
            "options": [
                "𝑊𝑥 + 𝐴𝐵𝑥",
                "𝑊𝑥 + 𝐴(𝐵𝑥)",
                "𝑊𝑥 + ∆𝑊𝑥, ∆𝑊 = 𝐴𝐵",
                "위 모든 표현은 동치이다."
            ],
            "correct": 3,
            "explanation": "LoRA는 저랭크 근사 ∆𝑊 = 𝐴𝐵를 추가하여, 𝑊𝑥 + ∆𝑊𝑥로 표현됩니다. 위 식들은 모두 동치입니다."
        }
    ]
}